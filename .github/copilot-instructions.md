# Copilot Instructions — Rates-and-Central-Bank-Dashboard ✅

Purpose
- Short, concrete guidance so an AI coding agent can be productive immediately in this repo.
- Focus: where to implement work, the exact contracts to maintain, and project-specific constraints.

Big picture (what matters)
- This repo is a rule-based macro dashboard divided into four orthogonal layers:
  1. Data ingestion: `Data/fetch_*.py` (fetchers return canonical ingestion objects — opaque to orchestration)
  2. Orchestration / Signals: `signals/` + `Update.py` (single source-of-truth JSON files)
  3. Analytics / Resolvers: `Analytics/*.py` and `Signals/resolve_*.py` (compute metrics and rule-based labels)
  4. UI: `UI/` (Streamlit; reads signals, displays evidence — do not modify when doing backend work)

Key files & conventions
- Orchestrator: implement behaviour in `update.py` (the repo currently has `Update.py` placeholder). Prefer lowercase `update.py` to match project docs and examples.
- ABI between layers: Do not reshape ingestion objects. Ingestors must return an opaque `{ INGESTION_OBJECT }` and orchestration must store it verbatim under `signals/raw_state.json`.
- Expected repo signals layout (must match exactly):
  - `signals/raw_state.json` (written by the orchestrator)
  - `signals/daily_state.json` (resolver output — do not write from orchestration)
- Analytics live in `Analytics/`; resolvers in `Signals/resolve_*.py` (rule-based logic that reads `raw_state.json` and writes `daily_state.json`).

Raw state contract (copy verbatim)
- Top-level JSON structure in `signals/raw_state.json` must be EXACTLY:
```
{
  "meta": { "generated_at": "ISO_UTC_TIMESTAMP", ... },
  "policy": { "effr": { INGESTION_OBJECT }, "cpi_yoy": { INGESTION_OBJECT } },
  "duration": { "y10_nominal": { INGESTION_OBJECT }, "y10_real": { INGESTION_OBJECT } },
  "volatility": { "vix": { INGESTION_OBJECT }, "move": { INGESTION_OBJECT } },
  "liquidity": { "rrp": { INGESTION_OBJECT }, "walcl": { INGESTION_OBJECT } }
}
```
- Important: **Do not flatten, rename, or interpret** these ingestion objects. Store them exactly as returned by fetchers.

Acceptance tests & behavioural expectations (must pass)
- `update.py` runs without crashing even if some fetchers fail or return `FAILED` values.
- `signals/raw_state.json` is always written (human-readable JSON, use `indent=2` to be diff-friendly).
- A lightweight `meta.data_health` summary must be present with top-level categories mapped to one of `OK | PARTIAL | FAILED` using mechanical rules:
  - OK = all sub-fields OK
  - PARTIAL = any combination of OK/FALLBACK/FAILED
  - FAILED = all FAILED
- Implement minimal tests (e.g., `tests/test_update.py`) validating the above behaviours (writing file, data_health rules, schema presence). Use plain `pytest`.

Validation helper (encouraged)
- Add a small helper (eg. `signals/validate.py` or inside `update.py`) that:
  - Asserts required top-level keys exist
  - Verifies ingestion objects contain required fields (when defined by the fetcher; otherwise allow opaque objects)
  - Fails fast with clear error messages if unexpected keys appear

Do / Don't (project-specific)
- ✅ Do: Preserve exact field names and nested structure returned by fetchers.
- ✅ Do: Keep orchestration mechanical and dumb — timestamps, health, pass-through storage.
- ✅ Do: Add focused unit tests for schema and writing behaviour.
- ❌ Don't: Implement business interpretation, metrics, label logic, or UI changes from orchestration work.
- ❌ Don't: Add new top-level keys or fields to `raw_state.json` that represent interpretation or derived signals.

Developer workflows & quick commands
- Run the orchestrator locally with: `python update.py` (or `python Update.py` for the current placeholder — standardize to `update.py`).
- Run tests with: `pytest` (add `tests/` when adding unit tests).
- Write JSON with `json.dump(..., indent=2, sort_keys=True)` so diffs are stable and human-readable.

Examples from this codebase
- Data fetchers live in `Data/fetch_policy.py`, `Data/fetch_yields.py`, `Data/fetch_vol.py`, `Data/fetch_liquidity.py` — return `{ INGESTION_OBJECT }`
- Orchestrator should import these fetchers and write `signals/raw_state.json` with `meta.generated_at` = ISO UTC timestamp.

When in doubt
- Follow the manifest above exactly. If an ingestion field's meaning isn't obvious, preserve it unchanged and add a unit test asserting preservation.

If you change anything in the schema
- Add a very short changelog entry in `README.md` and notify reviewers. Schema changes are high impact and must be explicit.

Questions / feedback
- Please review these instructions — tell me any missing examples or unclear constraints and I will iterate.

---
*File autogenerated/updated by Copilot instructions scan.*
